---
title: "LAB 8"
author: "Caroline He"
output:
  github_document:
    html_preview: false
  html_document: default
always_allow_html: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Learning goals
In this lab, you are expected to learn/put in practice the following skills:

* Evaluate whether a problem can be parallelized or not.
* Practice with the parallel package.
* Use Rscript to submit jobs
* Practice your skills with Git.

```{r}
library(microbenchmark)
```


1. This function generates a n x k dataset with all its entries distributed poission with mean lambda.
```{r}
# create matrix filling by rows
fun1 <- function(n = 100, k = 4, lambda = 4) {
  x <- NULL
  for (i in 1:n)
    x <- rbind(x, rpois(k, lambda))
}
# create matrix by how to fill (by columns)
fun1alt <- function(n = 100, k = 4, lambda = 4) {
  matrix(rpois(n*k, lambda), nrow = n, ncol = k)
}
# Benchmarking
microbenchmark::microbenchmark(
  fun1(n = 1000),
  fun1alt(n = 1000), unit = "relative"
)
```

2. Find the column max (hint: Checkout the function max.col()).
```{r}
# Data Generating Process (10 x 10,000 matrix)
set.seed(1234)
x <- matrix(rnorm(1e4), nrow=10)

# Find each column's max value
fun2 <- function(x) {
  apply(x, 2, max)
}

fun2alt <- function(x) {
  # position of the max value per row of x
  idx <- max.col(t(x))
  
 dim # Get the actual max value
  x[ cbind(idx, 1:ncol(x))]
}
# Do  we get the same?
all.equal(fun2(x), fun2alt(x))

# Benchmarking
microbenchmark::microbenchmark(
  fun2(x),
  fun2alt(x), unit = "relative"
)
```

3. Among its many uses, non-parametric bootstrapping allow us to obtain confidence intervals for parameter estimates without relying on parametric assumptions.

The main assumption is that we can approximate many experiments by resampling observations from our original dataset, which reflects the population.

This function implements the non-parametric bootstrap:

```{r}
library(parallel)
my_boot <- function(dat, stat, R, ncpus = 1L) {
  
  # Getting the random indices
  n <- nrow(dat)
  idx <- matrix(sample.int(n, n*R, TRUE), nrow=n, ncol=R)
 
  # Making the cluster using `ncpus`
  # STEP 1: GOES HERE
  cl <- makePSOCKcluster(ncpus)
  
  # STEP 2: GOES HERE
  clusterSetRNGStream(cl, 123) # equivalent to set.seed(123)
  clusterExport(cl, c("stat", "dat", "ids"))
  
  # STEP 3: THIS FUNCTION NEEDS TO BE REPLACES WITH parLapply
  ans <- lapply(seq_len(R), function(i) {
    stat(dat[idx[,i], , drop=FALSE])
  })
  
  # Coercing the list into a matrix
  ans <- do.call(rbind, ans)
  
  # STEP 4: GOES HERE
  stopCluster(cl)
  
  
  ans
  
}
```

1. Use the previous pseudocode, and make it work with parallel. Here is just an example for you to try:
```{r}
# Bootstrap of an OLS
my_stat <- function(d) coef(lm(y ~ x, data=d))

# DATA SIM
set.seed(1)
n <- 500; R <- 5e3

x <- cbind(rnorm(n)); y <- x*5 + rnorm(n)

# Checking if we get something similar as lm
ans0 <- confint(lm(y~x))
ans1 <- my_boot(dat = data.frame(x, y), my_stat, R = R, ncpus = 2L)

# You should get something like this
t(apply(ans1, 2, quantile, c(.025,.975)))
##                   2.5%      97.5%
## (Intercept) -0.1372435 0.05074397
## x            4.8680977 5.04539763
ans0
##                  2.5 %     97.5 %
## (Intercept) -0.1379033 0.04797344
## x            4.8650100 5.04883353

```

```{r}
system.time(my_boot(dat = data.frame(x, y), mi_stat, R = 4000, ncpus = 1L))
system.time(my_boot(dat = data.frame(x, y), mi_stat, R = 4000, ncpus = 2L))
```

