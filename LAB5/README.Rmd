---
title: "LAB 5"
author: "Caroline He"
date: "9/25/2021"
output: github_document
---

## Lab description
For this lab we will be, again, dealing with the meteorological dataset downloaded from the NOAA, the met. In this case, we will use data.table to answer some questions regarding the met dataset, while at the same time practice your Git+GitHub skills for this project.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part 1: Setup the Git project and the GitHub repository
now start working with the MET data.

## Setup in R
```{r packages}
# Set up R packages
library(data.table)
library(dtplyr)
library(dplyr)
```

```{r dataset}
# Download and read in the data
stations <- fread("ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.csv")
stations[, USAF := as.integer(USAF)]

# Dealing with NAs and 999999
stations[, USAF   := fifelse(USAF == 999999, NA_integer_, USAF)]
stations[, CTRY   := fifelse(CTRY == "", NA_character_, CTRY)]
stations[, STATE  := fifelse(STATE == "", NA_character_, STATE)]

# Selecting the three relevant columns, and keeping unique records
stations <- unique(stations[, list(USAF, CTRY, STATE)])

# Dropping NAs
stations <- stations[!is.na(USAF)]

# Removing duplicates
stations[, n := 1:.N, by = .(USAF)]
stations <- stations[n == 1,][, n := NULL]
```

```{r}
if (!file.exists("met_all.gz"))
  download.file(
    url = "https://raw.githubusercontent.com/USCbiostats/data-science-data/master/02_met/met_all.gz",
    destfile = "met_all.gz",
    method   = "libcurl",
    timeout  = 60
    )
met <- data.table::fread("met_all.gz")
```

```{r}
met <- merge(
  x     = met,
  y     = stations,
  by.x  = "USAFID",
  by.y  = "USAF",
  all.x = TRUE,
  all.y = FALSE
)
```

# Question 1: Representative station for the US
What is the median station in terms of temperature, wind speed, and atmospheric pressure? Look for the three weather stations that best represent continental US using the quantile() function. Do these three coincide?

Generate a representative version of each station. We will use the averages (median could be a good way to represent it, but it will depend on the case).
```{r collapsing by station}
station_averages <- met[,.(
  temp = mean(temp, na.rm = TRUE),
  wind.sp = mean(wind.sp, na.rm = TRUE),
  atm.press = mean(atm.press, na.rm = TRUE)
), by = .(USAFID)]
```

Identify median per variable
```{r quantiles}
medians <- station_averages[,.(
  temp_50 = quantile(temp, probs = .5, na.rm = TRUE),
  wind.sp_50 = quantile(wind.sp, probs = .5, na.rm = TRUE),
  atm.press_50 = quantile(atm.press, probs = .5, na.rm = TRUE)
)]
medians
```

Find stations that were the closest to these (hint: which.min())
```{r}
station_averages[, temp_dist := abs(temp - medians$temp_50)]
median_temp_station <- station_averages[order(temp_dist)][1] 

station_averages[, wind.sp_dist := abs(wind.sp - medians$wind.sp_50)]
median_wind.sp_station <- station_averages[order(wind.sp_dist)][1] 

station_averages[, atm.press_dist := abs(atm.press - medians$atm.press_50)]
median_atm.press_station <- station_averages[order(atm.press_dist)][1] 

median_temp_station
median_wind.sp_station
median_atm.press_station
station_averages
```
The median temperature station was `r median_temp_station$USAFID`

The median wind speed station was `r median_wind.sp_station$USAFID`

The median atm.press station was `r median_atm.press_station$USAFID`


# Question 2: Representative station per state
Just like the previous question, you are asked to identify what is the most representative, the median, station per state. This time, instead of looking at one variable at a time, look at the euclidean distance. If multiple stations show in the median, select the one located at the lowest latitude.

First recover states variables by merge
```{r}
station_averages <- merge(
  x = station_averages, y = stations, 
  by.x = "USAFID", by.y = "USAF",
  all.x = TRUE, all.y = FALSE
  )
station_averages
```

Now we can compute the median per state
```{r}
station_averages[, temp_50 := quantile(temp, probs = .5, na.rm = TRUE), by = STATE]
station_averages[, wind.sp_50 := quantile(wind.sp, probs = .5, na.rm = TRUE), by = STATE]
station_averages[, atm.press_50 := quantile(atm.press, probs = .5, na.rm = TRUE), by = STATE]
```

the euclidean distance is calculated by $\sqrt{\sum_i(x_i - y_i)^2}$.
```{r}
#calculation of euclidean distance
station_averages[,eudist := 
  sqrt((temp - temp_50)^2 + (wind.sp - wind.sp_50)^2) + 
  sqrt((temp - temp_50)^2 + (atm.press - atm.press_50)^2) +
  sqrt((wind.sp - wind.sp_50)^2 + (atm.press - atm.press_50)^2)]
#group by state
station_averages <- station_averages[ , .SD[which.min(eudist)], by = STATE]
station_averages
```



# Question 3: In the middle?
For each state, identify what is the station that is closest to the mid-point of the state. Combining these with the stations you identified in the previous question, use leaflet() to visualize all ~100 points in the same figure, applying different colors for those identified in this question.

Set up mid point data and calculate the euclidean distance by $\sqrt{\sum_i(x_i - y_i)^2}$.
```{r}
#create mid lat & mid lon
met[, lat_50 := quantile(lat, probs = .5, na.rm = TRUE), by = STATE]
met[, lon_50 := quantile(lon, probs = .5, na.rm = TRUE), by = STATE]
met[, eudist_mid := sqrt((lat - lat_50)^2 + (lon - lon_50)^2)]
#select columns
middle <- met[, list(USAFID, STATE, lat, lon, lat_50, lon_50, eudist_mid)]
middle <- middle[ , .SD[which.min(eudist_mid)], by = STATE]
```
Merge two data set
```{r}
#merge data with previous stations
station_midpoint <- merge(
  x = station_averages, y = middle,
  all.x = TRUE, all.y = FALSE,
  by = "USAFID")
station_midpoint <- rename(station_midpoint, STATE = STATE.x)
station_midpoint
```
Visualize data via leaflet()
```{r}
#library packages
library(leaflet)
#visualize via leaflet()
leaflet() %>%
  addProviderTiles('CartoDB.Positron') %>%
  addCircles(
    lat = ~lat, lng = ~lon, 
    color = 'light blue',
    opacity = 1,
    fillOpacity = 1,
    radius=100
)
```


# Question 4: Means of means
Using the quantile() function, generate a summary table that shows the number of states included, average temperature, wind-speed, and atmospheric pressure by the variable “average temperature level,” which you’ll need to create.

computing the states’ average temperature. Use that measurement to classify them according to the following criteria

* low: temp < 20
* Mid: temp >= 20 and temp < 25
* High: temp >= 25

Once you are done with that, you can compute the following:

* Number of entries (records),
* Number of NA entries,
* Number of stations,
* Number of states included, and
* Mean temperature, wind-speed, and atmospheric pressure.

```{r}
met[, state_temp := mean(temp, na.rm = TRUE), by = STATE]
met[, state_wind.sp := mean(wind.sp, na.rm = TRUE),by = STATE]
met[, state_atm.press := mean(atm.press, na.rm = TRUE),by = STATE]
met[, temp_cat := fifelse(
  state_temp < 20, "low-temp",
  fifelse(state_temp < 25, "mid-temp", "high-temp"))]
```
Lets make sure that we don't have NAs
```{r}
table(met$temp_cat, useNA = "always")
```
Summarize the data
```{r}
tab <- met[, .(
  N_entries = .N,
  N_stations = length(unique(USAFID)),
  avg_temp = mean(state_temp),
  avg_wind.sp = mean(state_wind.sp),
  avg_atm.press = mean(state_atm.press)
), by = temp_cat]

knitr::kable(tab)
```


